{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cb_dr.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f040c4dafee4060b32af716dd6ccad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_542031ef3fec49d98215663ee1abf1a8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bf6e40ea3f474899b3bbaaaae8e68040",
              "IPY_MODEL_ec07f40822e64a84980c90e51736b4b9"
            ]
          }
        },
        "542031ef3fec49d98215663ee1abf1a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf6e40ea3f474899b3bbaaaae8e68040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6521e7f503fd43aba2d52b55cc078589",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32c43150e8624cfbb606d9db776ce5c8"
          }
        },
        "ec07f40822e64a84980c90e51736b4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_529843d5045e47f8b948cc30b1290d28",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000000/1000000 [05:25&lt;00:00, 3076.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df5d26fbba8140ffb767b44fcbe7b5d1"
          }
        },
        "6521e7f503fd43aba2d52b55cc078589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32c43150e8624cfbb606d9db776ce5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "529843d5045e47f8b948cc30b1290d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df5d26fbba8140ffb767b44fcbe7b5d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7xOZcWpRYND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3b96d3b8-fa36-49a9-91c6-86c9f4de1c66"
      },
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z691WtQXRnLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0,nb_path)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIk0lA2DSMr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "from matplotlib import pyplot as plt\n",
        "from vowpalwabbit import pyvw\n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwPiW6XdSRdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "num_users = 5 \n",
        "num_ads = 10\n",
        "reward_table = {user: np.random.choice(10, size=num_ads) for user in range(num_users)}"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuc_HqhPS0R0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UniformlyRandom:\n",
        "    def __init__(self, num_actions):\n",
        "        \"\"\"\n",
        "        num_actions: number of actions (in this demo, it is equal to the number of ads)\n",
        "        \"\"\"\n",
        "        self.num_actions = num_actions \n",
        "\n",
        "    def choose_action(self, context):\n",
        "        \"\"\"\n",
        "        return a chosen action and action-probabilities\n",
        "        \"\"\"\n",
        "        return np.random.choice(self.num_actions), [1 / self.num_actions] * self.num_actions\n",
        "\n",
        "    def update(self, cb_sample):\n",
        "        \"\"\"\n",
        "        UniformlyRandom is a stateless policy, which means it does not update itself\n",
        "        based on the past rewards revelaed by it.\n",
        "\n",
        "        (parameters)\n",
        "        cb_sample: a tuple of (context, chosen action, reward revealed)\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YktsA93gS06N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EpsilonGreedy:\n",
        "    def __init__(self, num_actions, num_contexts, epsilon=0.1):\n",
        "        \"\"\"\n",
        "        This is a CB verision of epsilon greedy\n",
        "\n",
        "        (parameters)\n",
        "        num_actions: number of actions (= number of ads)\n",
        "        num_contexts: number of contexts (= number of users)\n",
        "        epsilon: this policy chooeses a random action with epsilon probability \n",
        "\n",
        "        (Stored values)\n",
        "        self.num_actions = num_actions \n",
        "        self.num_contexts = num_contexts\n",
        "        self.num_actions_chosen: keep track of how many times each action is chosen for each context\n",
        "        self.sum_rewards: keep track of the total reward of each action for each context\n",
        "\n",
        "        The reason why self.num_actions_chosen is initialized with np.ones instead of np.zeros is\n",
        "        to prevent division by zero in the function choose_action (line 68) \n",
        "        when an action has never been chosen so far for a given context.\n",
        "        \"\"\"\n",
        "        self.num_actions = num_actions \n",
        "        self.num_contexts = num_contexts\n",
        "        self.num_actions_chosen = {context: np.ones(num_actions) for context in range(num_contexts)}\n",
        "        self.sum_rewards = {context: np.zeros(num_actions) for context in range(num_contexts)}\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def choose_action(self, context):\n",
        "        \"\"\"\n",
        "        return a chosen action and its probability\n",
        "        \"\"\"\n",
        "        # Check which action is the best action \n",
        "        # The best action is the action that has the highest total reward for a given context\n",
        "        best_action = np.argmax(self.sum_rewards[context] / self.num_actions_chosen[context])\n",
        "\n",
        "        # Get action probabilities based on the best action\n",
        "        # there is a (epsilon + epsilon/num_actions) probability of choosing the best action.\n",
        "        # there is a (epsilon/num_actions) probability of choosing any other action\n",
        "        action_probabilities = [self.epsilon / self.num_actions] * self.num_actions\n",
        "        action_probabilities[best_action] += 1 - self.epsilon\n",
        "\n",
        "        # Sample an action\n",
        "        chosen_action = np.random.choice(self.num_actions, p=action_probabilities)\n",
        "\n",
        "        # Record the number of times the chosen action is chosen\n",
        "        self.num_actions_chosen[context][chosen_action] += 1\n",
        "\n",
        "        return chosen_action, action_probabilities\n",
        "\n",
        "    def update(self, cb_sample):\n",
        "        \"\"\"\n",
        "        EpsilonGreedy is a stateful policy, which means it does update itself\n",
        "        based on the past rewards revelaed by it.\n",
        "        Thus, update function is necessary.\n",
        "\n",
        "        (parameters)\n",
        "        cb_sample: a tuple of (context, chosen action, reward revealed)\n",
        "        \"\"\"\n",
        "        context, chosen_action, reward_revealed = cb_sample\n",
        "\n",
        "        self.sum_rewards[context][chosen_action] += reward_revealed"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1w3jXJ-S461",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StochasticPolicy:\n",
        "    def __init__(self, num_actions):\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "    def choose_action(self, context):\n",
        "        '''\n",
        "        Always chooses the first ad\n",
        "        '''\n",
        "        return (0, [1] + [0] * (self.num_actions - 1))\n",
        "\n",
        "    def update(self, cb_sample):\n",
        "        pass"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPYo4UuBTAiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeterministicPolicy:\n",
        "    def __init__(self, num_actions):\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "    def choose_action(self, context):\n",
        "        '''\n",
        "        Always chooses from ratio of 1:2:1:2:1:2 ... \n",
        "        '''\n",
        "        p = np.ones(self.num_actions)\n",
        "        for i in range(self.num_actions):\n",
        "            if i % 2 == 1:\n",
        "                p[i] = 2\n",
        "        p = p/np.sum(p)\n",
        "        chosen_action = np.random.choice(self.num_actions, p=p)\n",
        "        \n",
        "        return chosen_action, p\n",
        "\n",
        "    def update(self, cb_sample):\n",
        "        pass"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ2zdcuTVwlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IPS:\n",
        "    def __init__(self):\n",
        "        self.estimates = list()\n",
        "        self.name = 'IPS'\n",
        "\n",
        "    def get_estimate(self, old_probability, new_probability, reward):\n",
        "        \"\"\"\n",
        "        Append the IPS estimate of a single sample to self.estimates.\n",
        "        You should implement this function\n",
        "        \"\"\"\n",
        "        self.estimates.append((new_probability / old_probability) * reward)\n",
        "        \n",
        "\n",
        "    def evaluation(self, num_samples):\n",
        "        \"\"\"\n",
        "        Get the mean of num_samples number of IPS estimates\n",
        "        \"\"\"\n",
        "        return np.mean(self.estimates[:num_samples])\n",
        "\n",
        "    def bootstrap(self, num_samples, bootstrap_num, true_performance):\n",
        "        bootstrap_estimates = [self.evaluation(num_samples)]\n",
        "        \n",
        "        new_list = self.estimates[:num_samples]\n",
        "\n",
        "        for _ in range(1, bootstrap_num):\n",
        "            bootstrap_list = np.random.choice(new_list, size=num_samples)\n",
        "            bootstrap_estimates.append(np.mean(bootstrap_list))\n",
        "\n",
        "        errors_list = [abs(true_performance - estimate) / true_performance for estimate in bootstrap_estimates]\n",
        "\n",
        "        return np.mean(errors_list), np.std(errors_list)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8mgx0hsV2Et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DR:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr # learning rate\n",
        "        self.estimates = list()\n",
        "        self.Q = np.zeros((num_users, num_ads)) # Q-learning table\n",
        "        self.name = f'DR_{lr}'\n",
        "\n",
        "    def update_Q(self, context, action, reward):\n",
        "        \"Implement a function that updates Q\"\n",
        "        old = self.Q[context, action]\n",
        "        new = old + self.lr * (reward + 0*max(self.Q[context]) \n",
        "                - old)\n",
        "        self.Q[context, action] = new\n",
        "\n",
        "    def get_estimate(self, context, action, reward, old_probability, new_probabilities):\n",
        "        \"\"\"\n",
        "        Append the DR estimate of a single sample to self.estimates.\n",
        "        You should implement this function\n",
        "        \"\"\"\n",
        "        r_hat_x_v = np.matmul(np.array(new_probabilities), self.Q[context])\n",
        "        estimate = r_hat_x_v + (new_probabilities[action]/old_probability\n",
        "                                *(reward - self.Q[context, action]))\n",
        "        self.estimates.append(estimate)\n",
        "        self.update_Q(context, action, reward)\n",
        "\n",
        "\n",
        "    def evaluation(self, num_samples):\n",
        "        \"\"\"\n",
        "        Get the mean of num_samples number of IPS estimates\n",
        "        \"\"\"\n",
        "        return np.mean(self.estimates[:num_samples])\n",
        "\n",
        "    def bootstrap(self, num_samples, bootstrap_num, true_performance):\n",
        "        bootstrap_estimates = [self.evaluation(num_samples)]\n",
        "        \n",
        "        new_list = self.estimates[:num_samples]\n",
        "\n",
        "        for _ in range(1, bootstrap_num):\n",
        "            bootstrap_list = np.random.choice(new_list, size=num_samples)\n",
        "            bootstrap_estimates.append(np.mean(bootstrap_list))\n",
        "\n",
        "        errors_list = [abs(true_performance - estimate) / true_performance for estimate in bootstrap_estimates]\n",
        "\n",
        "        return np.mean(errors_list), np.std(errors_list)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h69vBhgxV9W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class DRVW:\n",
        "    def __init__(self, default_model=\"--power_t 0.0 -q ca --quiet\"):\n",
        "        self.estimates = list()\n",
        "        self.name = f'DRVW'\n",
        "        self.model = pyvw.vw(default_model)\n",
        "\n",
        "    def vw_format(self, context, action, reward=None):\n",
        "        \"\"\"\n",
        "        This function takes in a context and an action \n",
        "        and return a VW format string that contains the given inputs\n",
        "        \"\"\"\n",
        "\n",
        "        if reward is not None:\n",
        "            return f\"{reward} |c context{context} |a action{action}\"\n",
        "        else: \n",
        "            return f\"|c context{context} |a action{action}\"\n",
        "\n",
        "    def update_Q(self, context, action, reward):\n",
        "         \"Implement a function that updates Q\"\n",
        "         self.model.learn(self.vw_format(context, action, reward))\n",
        "\n",
        "    def get_Q(self, context, action):\n",
        "        \"Implement a function that retrieves a Q value from the VW model\"\n",
        "        return self.model.predict(self.vw_format(context, action))\n",
        "\n",
        "    def get_estimate(self, context, action, reward, old_probability, new_probabilities):\n",
        "        \"\"\"\n",
        "        Append the DR estimate of a single sample to self.estimates.\n",
        "        You should implement this function\n",
        "        \"\"\"\n",
        "        r_hat_x_v = np.matmul(np.array(new_probabilities), np.array([self.get_Q(context, i) \n",
        "                                                          for i in range(num_ads)]))\n",
        "        estimate = r_hat_x_v + (new_probabilities[action]/old_probability\n",
        "                                *(reward - self.get_Q(context, action)))\n",
        "        self.estimates.append(estimate)\n",
        "        self.update_Q(context, action, reward)\n",
        "        \n",
        "\n",
        "    def evaluation(self, num_samples):\n",
        "        \"\"\"\n",
        "        Get the mean of num_samples number of IPS estimates\n",
        "        \"\"\"\n",
        "        return np.mean(self.estimates[:num_samples])\n",
        "\n",
        "    def bootstrap(self, num_samples, bootstrap_num, true_performance):\n",
        "        bootstrap_estimates = [self.evaluation(num_samples)]\n",
        "        \n",
        "        new_list = self.estimates[:num_samples]\n",
        "\n",
        "        for _ in range(1, bootstrap_num):\n",
        "            bootstrap_list = np.random.choice(new_list, size=num_samples)\n",
        "            bootstrap_estimates.append(np.mean(bootstrap_list))\n",
        "\n",
        "        errors_list = [abs(true_performance - estimate) / true_performance for estimate in bootstrap_estimates]\n",
        "\n",
        "        return np.mean(errors_list), np.std(errors_list)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QeuLVPyTCqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uni_ran = UniformlyRandom(num_ads)\n",
        "eps_greedy = EpsilonGreedy(num_ads, num_users, epsilon=epsilon)\n",
        "sto = StochasticPolicy(num_ads)\n",
        "det = DeterministicPolicy(num_ads)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUGlZ7mVDqYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTl8Tk4kTRCI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712,
          "referenced_widgets": [
            "2f040c4dafee4060b32af716dd6ccad6",
            "542031ef3fec49d98215663ee1abf1a8",
            "bf6e40ea3f474899b3bbaaaae8e68040",
            "ec07f40822e64a84980c90e51736b4b9",
            "6521e7f503fd43aba2d52b55cc078589",
            "32c43150e8624cfbb606d9db776ce5c8",
            "529843d5045e47f8b948cc30b1290d28",
            "df5d26fbba8140ffb767b44fcbe7b5d1"
          ]
        },
        "outputId": "396b1ab8-1a30-4b3b-db77-212edba35acc"
      },
      "source": [
        "epsilon = 0.01 # epsilon is a tunable parameter\n",
        "# Start the demo\n",
        "num_samples = 1000000 # total number of samples. Feel free to change this if you want to\n",
        "new_policy_true_rewards = list() # Keep track of true rewards revealed by the new policy\n",
        "\n",
        "# Implement the demo as specified by the comments below\n",
        "old_policy = eps_greedy \n",
        "new_policy = uni_ran\n",
        "ips_estimator = IPS()\n",
        "dr_estimator1 = DR(lr=1)\n",
        "dr_estimator2 = DR(lr=0.1)\n",
        "dr_estimator3 = DR(lr=0.01)\n",
        "drvw_estimator = DRVW()\n",
        "\n",
        "for sample_index in tqdm(range(num_samples)): \n",
        "    # Context (user) revealed\n",
        "    user = np.random.choice(num_users)\n",
        "\n",
        "    # The old policy chooses an action\n",
        "    old_chosen_action, old_probabilities = old_policy.choose_action(user)\n",
        "\n",
        "    # The reward of the action chosen by the old policy is revealed\n",
        "    reward = reward_table[user][old_chosen_action]\n",
        "\n",
        "    # The new policy chooses an action\n",
        "    new_chosen_action, new_probabilities = new_policy.choose_action(user)\n",
        "\n",
        "    # Record the reward revealed by the new policy to get the true performance of the new policy\n",
        "    new_policy_true_rewards.append(reward_table[user][new_chosen_action])\n",
        "\n",
        "    # Store the CB sample in trace for evaluation\n",
        "    ips_estimator.get_estimate(old_probabilities[old_chosen_action], new_probabilities[old_chosen_action],\n",
        "                              reward)\n",
        "    # Get DR estimate\n",
        "    dr_estimator1.get_estimate(user, old_chosen_action, reward, old_probabilities[old_chosen_action], new_probabilities)\n",
        "    dr_estimator2.get_estimate(user, old_chosen_action, reward, old_probabilities[old_chosen_action], new_probabilities)\n",
        "    dr_estimator3.get_estimate(user, old_chosen_action, reward, old_probabilities[old_chosen_action], new_probabilities)\n",
        "    drvw_estimator.get_estimate(user, old_chosen_action, reward, old_probabilities[old_chosen_action], new_probabilities)\n",
        "    # Update the old policy if needed\n",
        "    old_policy.update((user, old_chosen_action, reward))\n",
        "\n",
        "true_performance = np.mean(new_policy_true_rewards)\n",
        "\n",
        "# List the error of each estimator\n",
        "estimators = [ips_estimator, dr_estimator1, dr_estimator2, dr_estimator3, drvw_estimator]\n",
        "bootstrap_num = 20\n",
        "\n",
        "means = [np.zeros(5), np.zeros(5), np.zeros(5), np.zeros(5), np.zeros(5)]\n",
        "stds = [np.zeros(5), np.zeros(5), np.zeros(5), np.zeros(5), np.zeros(5)]\n",
        "\n",
        "for j, estimator in enumerate(estimators):\n",
        "    print(estimator.name)\n",
        "    for i in range(2, 7):\n",
        "        num_samples = int(10**i)\n",
        "        mean, std = estimator.bootstrap(num_samples, bootstrap_num, true_performance)\n",
        "        means[j][i-2] = mean\n",
        "        stds[j][i-2] = std\n",
        "        print(f\"(num_samples: {num_samples}): (mean: {mean} / std: {std})\")\n",
        "    print()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f040c4dafee4060b32af716dd6ccad6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1000000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "IPS\n",
            "(num_samples: 100): (mean: 0.6407157511176899 / std: 0.5293859911935999)\n",
            "(num_samples: 1000): (mean: 0.3174306592815036 / std: 0.1978472345860374)\n",
            "(num_samples: 10000): (mean: 0.09324952688899532 / std: 0.05790311615396456)\n",
            "(num_samples: 100000): (mean: 0.026143505945340685 / std: 0.02497999947087137)\n",
            "(num_samples: 1000000): (mean: 0.015951918516130405 / std: 0.009608253060182688)\n",
            "\n",
            "DR_1\n",
            "(num_samples: 100): (mean: 0.49672799777513843 / std: 0.36834158137319906)\n",
            "(num_samples: 1000): (mean: 0.25820526793932885 / std: 0.17828426100704048)\n",
            "(num_samples: 10000): (mean: 0.08988847474043117 / std: 0.05147702359128832)\n",
            "(num_samples: 100000): (mean: 0.0076951676752752204 / std: 0.005906275367914946)\n",
            "(num_samples: 1000000): (mean: 0.0011340028651474754 / std: 0.0006453574565239947)\n",
            "\n",
            "DR_0.1\n",
            "(num_samples: 100): (mean: 0.5599031439781699 / std: 0.5177899780530487)\n",
            "(num_samples: 1000): (mean: 0.3255981600487323 / std: 0.15019726173337605)\n",
            "(num_samples: 10000): (mean: 0.061030339288290936 / std: 0.045762671512207344)\n",
            "(num_samples: 100000): (mean: 0.01999930277273207 / std: 0.013268715381941411)\n",
            "(num_samples: 1000000): (mean: 0.0015846129739341588 / std: 0.001097544718589036)\n",
            "\n",
            "DR_0.01\n",
            "(num_samples: 100): (mean: 0.5287994590451249 / std: 0.3529906603028371)\n",
            "(num_samples: 1000): (mean: 0.3106518546500383 / std: 0.23462386620699952)\n",
            "(num_samples: 10000): (mean: 0.07316000389512238 / std: 0.060179560602898356)\n",
            "(num_samples: 100000): (mean: 0.02823391785356132 / std: 0.020797041908792196)\n",
            "(num_samples: 1000000): (mean: 0.0067035349625666945 / std: 0.00402374472553238)\n",
            "\n",
            "DRVW\n",
            "(num_samples: 100): (mean: 1.2020544835540916 / std: 1.026772296684799)\n",
            "(num_samples: 1000): (mean: 0.3720509895580222 / std: 0.17097921086098733)\n",
            "(num_samples: 10000): (mean: 0.053187526985210766 / std: 0.04162934866731479)\n",
            "(num_samples: 100000): (mean: 0.010149393468821143 / std: 0.0063682271744700805)\n",
            "(num_samples: 1000000): (mean: 0.0012396893604379783 / std: 0.0007762891146430768)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4BUKtYylBqL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "d2c69b5d-bc41-4fc2-eb19-2053d82b6ba0"
      },
      "source": [
        "# Table that shows how accurate the DM estimate of the DR_0.1 estimator is\n",
        "for i in range(num_users):\n",
        "  for j in range(num_ads):\n",
        "    reward = reward_table[i][j]\n",
        "\n",
        "    print(f\"{(i,j)}: {reward} / {dr_estimator2.Q[i, j]} / {reward - dr_estimator2.Q[i, j]}\")\n",
        "  print()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 0): 5 / 4.999999998633358 / 1.366641910749422e-09\n",
            "(0, 1): 0 / 0.0 / 0.0\n",
            "(0, 2): 3 / 2.999999999088906 / 9.110938670175983e-10\n",
            "(0, 3): 3 / 2.999999992506012 / 7.493988096740622e-09\n",
            "(0, 4): 7 / 6.999999895150309 / 1.0484969070745365e-07\n",
            "(0, 5): 9 / 8.999999999999993 / 7.105427357601002e-15\n",
            "(0, 6): 3 / 2.9999999970966758 / 2.9033242476828036e-09\n",
            "(0, 7): 5 / 4.999999978848107 / 2.1151892681814388e-08\n",
            "(0, 8): 2 / 1.9999999998610476 / 1.3895240513761564e-10\n",
            "(0, 9): 4 / 3.9999999994770725 / 5.229274790963245e-10\n",
            "\n",
            "(1, 0): 7 / 6.999999976013754 / 2.398624587840459e-08\n",
            "(1, 1): 6 / 5.999999991149751 / 8.8502494222098e-09\n",
            "(1, 2): 8 / 7.999999998565356 / 1.4346444032753425e-09\n",
            "(1, 3): 8 / 7.9999999999999964 / 3.552713678800501e-15\n",
            "(1, 4): 1 / 0.9999999969160541 / 3.083945876447558e-09\n",
            "(1, 5): 6 / 5.99999994103553 / 5.8964469751288107e-08\n",
            "(1, 6): 7 / 6.9999999939030175 / 6.096982474446122e-09\n",
            "(1, 7): 7 / 6.999999963441174 / 3.655882618858186e-08\n",
            "(1, 8): 8 / 7.99999999944419 / 5.558096205504626e-10\n",
            "(1, 9): 1 / 0.9999999992161024 / 7.838976134877385e-10\n",
            "\n",
            "(2, 0): 5 / 4.999999998770022 / 1.2299778973101638e-09\n",
            "(2, 1): 9 / 8.999999911553294 / 8.844670595919979e-08\n",
            "(2, 2): 8 / 7.999999977795589 / 2.2204410754511628e-08\n",
            "(2, 3): 9 / 8.999999999999993 / 7.105427357601002e-15\n",
            "(2, 4): 4 / 3.999999974208941 / 2.579105906619361e-08\n",
            "(2, 5): 3 / 2.9999999907481625 / 9.251837518320372e-09\n",
            "(2, 6): 0 / 0.0 / 0.0\n",
            "(2, 7): 3 / 2.9999999970966758 / 2.9033242476828036e-09\n",
            "(2, 8): 5 / 4.999999994026081 / 5.973919137147732e-09\n",
            "(2, 9): 0 / 0.0 / 0.0\n",
            "\n",
            "(3, 0): 2 / 1.9999999993251159 / 6.748841485659796e-10\n",
            "(3, 1): 3 / 2.999999985898738 / 1.4101261935905995e-08\n",
            "(3, 2): 8 / 7.9999999999999964 / 3.552713678800501e-15\n",
            "(3, 3): 1 / 0.9999999999973493 / 2.6506574712925612e-12\n",
            "(3, 4): 3 / 2.9999999978834766 / 2.1165234009856704e-09\n",
            "(3, 5): 3 / 2.999999994536883 / 5.463117069837153e-09\n",
            "(3, 6): 3 / 2.999999998750214 / 1.249786052426316e-09\n",
            "(3, 7): 7 / 6.999999997083832 / 2.9161677517208773e-09\n",
            "(3, 8): 0 / 0.0 / 0.0\n",
            "(3, 9): 1 / 0.9999999996625579 / 3.374420742829898e-10\n",
            "\n",
            "(4, 0): 9 / 8.999999999999993 / 7.105427357601002e-15\n",
            "(4, 1): 9 / 8.999999997266716 / 2.733283821498844e-09\n",
            "(4, 2): 0 / 0.0 / 0.0\n",
            "(4, 3): 4 / 3.9999999979427394 / 2.0572605841095992e-09\n",
            "(4, 4): 7 / 6.999999994512716 / 5.487284404637194e-09\n",
            "(4, 5): 3 / 2.9999999978834766 / 2.1165234009856704e-09\n",
            "(4, 6): 2 / 1.9999999989713697 / 1.0286302920547996e-09\n",
            "(4, 7): 7 / 6.999999995061444 / 4.938556230627e-09\n",
            "(4, 8): 2 / 1.9999999992501287 / 7.498712761844217e-10\n",
            "(4, 9): 0 / 0.0 / 0.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSJyEI0tlgpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "0fdd6c54-fc2e-421e-bce5-a75f48994f84"
      },
      "source": [
        "# Table that shows how accurate the DM estimate of the DRVW estimator is\n",
        "for i in range(num_users):\n",
        "  for j in range(num_ads):\n",
        "    reward = reward_table[i][j]\n",
        "\n",
        "    print(f\"{(i,j)}: {reward} / {drvw_estimator.get_Q(i, j)} / {reward - drvw_estimator.get_Q(i, j)}\")\n",
        "  print()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 0): 5 / 5.0 / 0.0\n",
            "(0, 1): 0 / 0.0 / 0.0\n",
            "(0, 2): 3 / 2.999999761581421 / 2.384185791015625e-07\n",
            "(0, 3): 3 / 2.999999761581421 / 2.384185791015625e-07\n",
            "(0, 4): 7 / 7.0 / 0.0\n",
            "(0, 5): 9 / 9.0 / 0.0\n",
            "(0, 6): 3 / 3.0 / 0.0\n",
            "(0, 7): 5 / 5.0 / 0.0\n",
            "(0, 8): 2 / 2.0 / 0.0\n",
            "(0, 9): 4 / 3.999999761581421 / 2.384185791015625e-07\n",
            "\n",
            "(1, 0): 7 / 7.0 / 0.0\n",
            "(1, 1): 6 / 6.0 / 0.0\n",
            "(1, 2): 8 / 8.0 / 0.0\n",
            "(1, 3): 8 / 8.0 / 0.0\n",
            "(1, 4): 1 / 1.0 / 0.0\n",
            "(1, 5): 6 / 6.0 / 0.0\n",
            "(1, 6): 7 / 7.0 / 0.0\n",
            "(1, 7): 7 / 7.0 / 0.0\n",
            "(1, 8): 8 / 7.999999523162842 / 4.76837158203125e-07\n",
            "(1, 9): 1 / 0.9999992847442627 / 7.152557373046875e-07\n",
            "\n",
            "(2, 0): 5 / 5.0 / 0.0\n",
            "(2, 1): 9 / 9.0 / 0.0\n",
            "(2, 2): 8 / 8.0 / 0.0\n",
            "(2, 3): 9 / 9.0 / 0.0\n",
            "(2, 4): 4 / 4.0 / 0.0\n",
            "(2, 5): 3 / 3.000000238418579 / -2.384185791015625e-07\n",
            "(2, 6): 0 / 2.384185791015625e-07 / -2.384185791015625e-07\n",
            "(2, 7): 3 / 3.0 / 0.0\n",
            "(2, 8): 5 / 5.0 / 0.0\n",
            "(2, 9): 0 / 0.0 / 0.0\n",
            "\n",
            "(3, 0): 2 / 2.0 / 0.0\n",
            "(3, 1): 3 / 3.0 / 0.0\n",
            "(3, 2): 8 / 8.0 / 0.0\n",
            "(3, 3): 1 / 1.0 / 0.0\n",
            "(3, 4): 3 / 3.0 / 0.0\n",
            "(3, 5): 3 / 3.0 / 0.0\n",
            "(3, 6): 3 / 3.0 / 0.0\n",
            "(3, 7): 7 / 7.0 / 0.0\n",
            "(3, 8): 0 / 0.0 / 0.0\n",
            "(3, 9): 1 / 0.9999998211860657 / 1.7881393432617188e-07\n",
            "\n",
            "(4, 0): 9 / 9.0 / 0.0\n",
            "(4, 1): 9 / 9.0 / 0.0\n",
            "(4, 2): 0 / 0.0 / 0.0\n",
            "(4, 3): 4 / 4.0 / 0.0\n",
            "(4, 4): 7 / 6.999999523162842 / 4.76837158203125e-07\n",
            "(4, 5): 3 / 3.000000238418579 / -2.384185791015625e-07\n",
            "(4, 6): 2 / 2.0 / 0.0\n",
            "(4, 7): 7 / 7.0 / 0.0\n",
            "(4, 8): 2 / 2.0 / 0.0\n",
            "(4, 9): 0 / 0.0 / 0.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpb5K0i48_Eg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "77066901-9fdd-49cc-d512-3043439b87b9"
      },
      "source": [
        "color = ['r', 'b', 'y', 'g', 'k']\n",
        "x = np.array([10]*5)**range(2, 7)\n",
        "for i in range(5):\n",
        "  plt.errorbar(x, means[i], yerr=stds[i], color=color[i])\n",
        "plt.xscale('log')\n",
        "plt.legend(['IPS', 'DR_1', 'DR_0.1', 'DR_0.01', 'DRVW'])\n",
        "plt.show()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}